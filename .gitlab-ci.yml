# x0tta6bl4 Repository CI/CD Pipeline
# Includes: hygiene checks, DVC validation, security scanning

stages:
  - validate
  - ebpf-build
  - test
  - security
  - android-build
  - build
  - deploy

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  DVC_CACHE_DIR: "$CI_PROJECT_DIR/.cache/dvc"

# === Repository Hygiene Checks ===

repo-hygiene:
  stage: validate
  image: python:3.11-slim
  before_script:
    - apt-get update && apt-get install -y git findutils
  script:
    - echo "ðŸ” Checking repository hygiene..."

    # Check for accidentally committed virtual environments
    - |
      if find . -type d \( -name 'venv' -o -name '.venv' -o -name 'venv_*' \) ! -path './.git/*' | grep -q .; then
        echo "âŒ ERROR: Virtual environments detected in repository!"
        find . -type d \( -name 'venv' -o -name '.venv' -o -name 'venv_*' \) ! -path './.git/*'
        exit 1
      fi

    # Check for database files (only migrations should be in Git)
    - |
      if find . -name '*.db' -o -name '*.sqlite*' ! -path './.git/*' | grep -q .; then
        echo "âŒ ERROR: Database files detected in repository!"
        echo "Only migrations should be committed. Found:"
        find . -name '*.db' -o -name '*.sqlite*' ! -path './.git/*'
        exit 1
      fi

    # Check for large files (>10MB)
    - |
      LARGE_FILES=$(find . -type f -size +10M ! -path './.git/*' ! -path './.cache/*')
      if [ -n "$LARGE_FILES" ]; then
        echo "âŒ ERROR: Large files (>10MB) detected:"
        echo "$LARGE_FILES" | xargs -I {} du -h {}
        echo "Use DVC or move to artifact storage!"
        exit 1
      fi

    # Check for archives that shouldn't be in Git
    - |
      ARCHIVES=$(find . -type f \( -name '*.tar.gz' -o -name '*.zip' -o -name '*.tgz' \) ! -path './.git/*' ! -path './external_artifacts/*')
      if [ -n "$ARCHIVES" ]; then
        echo "âš ï¸  WARNING: Archive files found outside external_artifacts/:"
        echo "$ARCHIVES"
        echo "Consider moving to external artifact storage."
      fi

    # Check for accidentally committed secrets
    - |
      if find . -name '.env' ! -path './.git/*' | grep -q .; then
        echo "âŒ ERROR: .env file detected in repository!"
        find . -name '.env' ! -path './.git/*'
        exit 1
      fi

    - echo "âœ… Repository hygiene check passed!"
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: false

# === eBPF Programs Compilation ===

ebpf-compile:
  stage: ebpf-build
  image: ubuntu:latest
  cache:
    key: "ebpf-${CI_COMMIT_REF_SLUG}"
    paths:
      - src/network/ebpf/programs/vmlinux/
  before_script:
    - apt-get update && apt-get install -y --no-install-recommends
        clang
        llvm
        libelf-dev
        libz-dev
        pkg-config
        linux-headers-generic
        make
        file
        bpftool
  script:
    - echo "ðŸ”¨ Compiling x0tta6bl4 eBPF programs..."
    - mkdir -p build/ebpf
    - cd src/network/ebpf/programs
    - echo "ðŸ“¦ Generating CO-RE headers (vmlinux.h)..."
    - make vmlinux || echo "âš ï¸  CO-RE not available, continuing without vmlinux.h"
    - echo "ðŸ”¨ Compiling all eBPF programs..."
    - make clean
    - make all
    - echo "âœ… Compilation successful"
    - echo ""
    - echo "ðŸ“Š Compiled objects:"
    - ls -lh *.o 2>/dev/null || echo "No object files"
    - cd - && cp src/network/ebpf/programs/*.o build/ebpf/
  artifacts:
    paths:
      - build/ebpf/*.o
    reports:
      junit: build/ebpf/*.xml
    expire_in: 30 days
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
      changes:
        - src/network/ebpf/programs/**
        - .gitlab-ci.yml
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - src/network/ebpf/programs/**
        - .gitlab-ci.yml
  allow_failure: false
  timeout: 10 minutes

ebpf-verify:
  stage: ebpf-build
  image: ubuntu:latest
  dependencies:
    - ebpf-compile
  before_script:
    - apt-get update && apt-get install -y --no-install-recommends
        llvm
        python3
        python3-pip
        file
        binutils
  script:
    - echo "ðŸ” Verifying eBPF programs..."
    - |
      if [ ! -d "build/ebpf" ] || [ -z "$(ls build/ebpf/*.o 2>/dev/null)" ]; then
        echo "âŒ No eBPF objects found in build/ebpf/"
        exit 1
      fi
    - echo "ðŸ“‹ Checking ELF format..."
    - |
      for obj in build/ebpf/*.o; do
        objname=$(basename "$obj")
        echo "  Checking $objname..."
        if file "$obj" | grep -q "ELF.*BPF"; then
          echo "    âœ… Valid eBPF object"
        else
          echo "    âŒ INVALID ELF format"
          file "$obj"
          exit 1
        fi
      done
    - echo "ðŸ“Š Disassembling programs (first 30 lines)..."
    - |
      for obj in build/ebpf/*.o; do
        objname=$(basename "$obj")
        echo "  $objname:"
        llvm-objdump -d "$obj" 2>/dev/null | head -30 || echo "    (Could not disassemble)"
      done
    - echo "ðŸ”§ Validating with Python ELF parser..."
    - pip3 install -q pyelftools
    - |
      python3 << 'EOF'
      import os
      import sys
      from elftools.elf.elffile import ELFFile

      success = True
      for filename in os.listdir('build/ebpf'):
          if not filename.endswith('.o'):
              continue

          filepath = os.path.join('build/ebpf', filename)
          try:
              with open(filepath, 'rb') as f:
                  elf = ELFFile(f)
                  machine = elf['e_machine']
                  if machine == 'EM_BPF':
                      print(f"âœ… {filename} - Valid eBPF (machine={machine})")
                  else:
                      print(f"âŒ {filename} - INVALID machine type: {machine}")
                      success = False
          except Exception as e:
              print(f"âŒ {filename} - Error: {e}")
              success = False

      if not success:
          sys.exit(1)
      EOF
    - echo "ðŸŽ‰ All eBPF programs verified!"
  artifacts:
    paths:
      - build/ebpf/*.o
    expire_in: 30 days
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
      changes:
        - src/network/ebpf/programs/**
        - .gitlab-ci.yml
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - src/network/ebpf/programs/**
        - .gitlab-ci.yml
  allow_failure: false
  timeout: 10 minutes

# === DVC Validation ===

dvc-validation:
  stage: validate
  image: python:3.11-slim
  before_script:
    - pip install dvc dvc-s3
  script:
    - echo "ðŸ“¦ Validating DVC setup..."

    # Check DVC is initialized
    - |
      if [ ! -d ".dvc" ]; then
        echo "âš ï¸  WARNING: DVC not initialized in this repository."
        echo "Run: dvc init"
        exit 0  # Don't fail if DVC not set up yet
      fi

    # Validate .dvc files
    - dvc status || echo "âš ï¸  Some DVC files may be out of sync"

    # Dry-run pull to check remote connectivity
    - dvc pull --dry-run || echo "âš ï¸  Cannot connect to DVC remote (expected in CI)"

    # Check for large files that should be in DVC
    - |
      echo "Checking for DVC candidates..."
      find data/ -type f \( -name '*.csv' -o -name '*.jsonl' -o -name '*.parquet' \) -size +5M 2>/dev/null | while read file; do
        if [ ! -f "${file}.dvc" ]; then
          echo "âš ï¸  Large file not tracked by DVC: $file"
        fi
      done

    - echo "âœ… DVC validation complete"
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: true  # Don't block pipeline if DVC not fully set up

# === Security Scanning ===

pip-audit-scan:
  stage: security
  image: python:3.11-slim
  before_script:
    - pip install pip-audit
  script:
    - echo "ðŸ” Running pip-audit for dependency vulnerabilities..."
    - pip-audit -r requirements.txt --no-deps --disable-pip || { echo "âŒ pip-audit found vulnerabilities in pinned requirements!"; exit 1; }
    - echo "âœ… pip-audit scan complete"
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: false # Ensure failure for security issues

secrets-scan:
  stage: security
  image: python:3.11-slim
  before_script:
    - pip install detect-secrets
  script:
    - echo "ðŸ” Scanning for secrets..."
    - detect-secrets scan --all-files --force-use-all-plugins || { echo "âŒ Secrets detected!"; exit 1; }
    - echo "âœ… No secrets detected"
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: false # Ensure failure for security issues

bandit-scan:
  stage: security
  image: python:3.11-slim
  before_script:
    - pip install bandit
  script:
    - echo "ðŸ” Running Bandit security linter..."
    - bandit -r src/ -ll -f json -o bandit-report.json || { echo "âŒ Bandit found medium/high security issues!"; exit 1; }
    - echo "âœ… Bandit scan complete"
  artifacts:
    paths:
      - bandit-report.json
    expire_in: 30 days
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: false # Ensure failure for security issues

safety-scan:
  stage: security
  image: python:3.11-slim
  before_script:
    - pip install safety
  script:
    - echo "ðŸ” Running Safety dependency vulnerability scanner..."
    - |
      if safety scan --target . --output json --save-as json safety-report.json; then
        echo "âœ… Safety scan complete"
      elif [ -n "${SAFETY_API_KEY:-}" ]; then
        echo "âŒ Safety scan failed with SAFETY_API_KEY configured."
        exit 1
      else
        echo "âš ï¸ Safety scan unavailable/auth-gated in CI environment; skipping hard-fail."
      fi
    - echo "â„¹ï¸ Safety stage finished"
  artifacts:
    paths:
      - safety-report.json
    expire_in: 30 days
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: false # Ensure failure for security issues

trivy-scan:
  stage: security
  image:
    name: aquasec/trivy:latest
    entrypoint: [""]
  dependencies:
    - docker-build # Depend on docker-build to get image metadata
  script:
    - echo "ðŸ” Running Trivy vulnerability scan for Docker image..."
    - IMAGE_DETAILS=$(cat image_metadata.json) # Get image details from artifacts
    - IMAGE_NAME=$(echo "$IMAGE_DETAILS" | jq -r '.image')
    - IMAGE_TAG=$(echo "$IMAGE_DETAILS" | jq -r '.tag')
    - FULL_IMAGE_NAME="${IMAGE_NAME}:${IMAGE_TAG}"
    - trivy image --exit-code 1 --severity HIGH,CRITICAL --format template --template "@contrib/gitlab.tpl" --output trivy-report.json "$FULL_IMAGE_NAME" || { echo "âŒ Trivy found vulnerabilities!"; exit 1; }
    - echo "âœ… Trivy scan complete"
  artifacts:
    paths:
      - trivy-report.json
    reports:
      container_scanning: trivy-report.json
    expire_in: 30 days
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: true # Allow failure for now, will be false in production


# === Android Build & PQC Signing ===

android-apk-sign:
  stage: android-build
  image: gradle:latest # or a custom image with Android SDK, JDK, Python
  before_script:
    - apt-get update && apt-get install -y --no-install-recommends python3 python3-pip git
    - pip install liboqs-python # For PQC signing
    - chmod +x universal_build.sh pqc_signer.py # Ensure scripts are executable
  script:
    - echo "ðŸ—ï¸ Building Android APK..."
    - ./universal_build.sh --android --release # Build the APK
    - APK_PATH=$(find . -name "*.apk" | head -n 1) # Find the first APK
    - echo "ðŸ” Found APK at: $APK_PATH"
    - if [ -z "$APK_PATH" ]; then echo "âŒ No APK found!"; exit 1; fi
    - echo "ðŸ” PQC Signing APK..."
    - if [ -z "$PQC_SIGNING_PRIVATE_KEY" ]; then echo "âŒ PQC_SIGNING_PRIVATE_KEY is not set!"; exit 1; fi
    - python3 pqc_signer.py sign --file "$APK_PATH" --private-key "$PQC_SIGNING_PRIVATE_KEY" > "${APK_PATH}.sig"
    - echo "âœ… APK PQC Signed: ${APK_PATH}.sig"
  artifacts:
    paths:
      - "*.apk"
      - "*.apk.sig"
    expire_in: 30 days
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
      changes:
        - app/** # Assuming Android project is in 'app' directory
        - universal_build.sh
        - pqc_signer.py
        - .gitlab-ci.yml
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - app/**
        - universal_build.sh
        - pqc_signer.py
        - .gitlab-ci.yml
  allow_failure: false
  timeout: 20 minutes

# === Python Linting & Type Checking ===

python-quality:
  stage: validate
  image: python:3.11-slim
  before_script:
    - pip install ruff mypy
  script:
    - echo "ðŸ” Running code quality checks..."
    - ruff check . || true  # Don't fail yet, just warn
    - mypy . --ignore-missing-imports || true
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: true

# === Unit Tests ===

unit-tests:
  stage: test
  image: python:3.11
  before_script:
    - pip install -r requirements-dev.txt || true
    - pip install -r requirements.txt || true
    - pip install pytest pytest-asyncio pytest-mock pytest-cov
  script:
    - echo "ðŸ§ª Running deterministic coverage gate (core/api/security)..."
    - export PYTHONFAULTHANDLER=1
    - timeout 25m bash x0tta6bl4-core-skill/x0tta6bl4-core/scripts/check_test_coverage.sh
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    paths:
      - htmlcov/
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  timeout: 30 minutes

# === Benchmark Thresholds Check ===

benchmark-thresholds:
  stage: test
  image: python:3.11
  before_script:
    - pip install -r requirements.txt || true
    - pip install httpx  # For benchmark scripts
  script:
    - echo "ðŸ“Š Checking benchmark thresholds..."
    - |
      if [ -f "benchmarks/baseline/baseline.json" ] && [ -f "benchmarks/results/latest.json" ]; then
        python scripts/check_benchmark_thresholds.py \
          --baseline benchmarks/baseline/baseline.json \
          --current benchmarks/results/latest.json \
          --threshold 0.10 || echo "âš ï¸ Benchmark degradation detected (non-blocking for now)"
      else
        echo "âš ï¸ Baseline or latest results not found, skipping threshold check"
        echo "Run: ./scripts/run_baseline_benchmarks.sh to establish baseline"
      fi
  artifacts:
    paths:
      - benchmarks/results/*.json
    expire_in: 30 days
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  allow_failure: true  # Non-blocking for now, will be mandatory in Phase 3.3

# === Docker Build (Immutable Images) ===

docker-build:
  stage: build
  image: docker:24-git
  services:
    - docker:24-dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - chmod +x scripts/build_immutable_image.sh
  script:
    - echo "ðŸ”¨ Building immutable Docker image with content-addressable tags..."
    - |
      # Build with content-addressable tags
      COMMIT_SHA="${CI_COMMIT_SHA}"
      SHORT_SHA="${COMMIT_SHA:0:12}"
      
      # Build image
      docker build -f Dockerfile.app \
        -t ${CI_REGISTRY_IMAGE}:${COMMIT_SHA} \
        -t ${CI_REGISTRY_IMAGE}:sha256-${SHORT_SHA} \
        -t ${CI_REGISTRY_IMAGE}:latest \
        .
      
      # Push all tags
      docker push ${CI_REGISTRY_IMAGE}:${COMMIT_SHA}
      docker push ${CI_REGISTRY_IMAGE}:sha256-${SHORT_SHA}
      docker push ${CI_REGISTRY_IMAGE}:latest || true
      
      # Get image digest (content-addressable)
      IMAGE_DIGEST=$(docker inspect --format='{{index .RepoDigests 0}}' ${CI_REGISTRY_IMAGE}:${COMMIT_SHA} 2>/dev/null || echo "")
      
      echo "âœ… Image built and pushed:"
      echo "  - Tag: ${CI_REGISTRY_IMAGE}:${COMMIT_SHA}"
      echo "  - SHA256 tag: ${CI_REGISTRY_IMAGE}:sha256-${SHORT_SHA}"
      echo "  - Digest: ${IMAGE_DIGEST}"
      
      # Save metadata for deployment
      echo "{\"image\":\"${CI_REGISTRY_IMAGE}\",\"tag\":\"${COMMIT_SHA}\",\"sha256_tag\":\"sha256-${SHORT_SHA}\",\"digest\":\"${IMAGE_DIGEST}\"}" > image_metadata.json
  artifacts:
    paths:
      - image_metadata.json
    expire_in: 30 days
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "develop"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'

# === Deployment ===

deploy-staging:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache curl
  script:
    - echo "ðŸš€ Deploying to staging..."
    - curl -X POST $STAGING_WEBHOOK_URL -d "version=$CI_COMMIT_SHA"
  rules:
    - if: '$CI_COMMIT_BRANCH == "develop"'
  environment:
    name: staging
    url: https://staging.x0tta6bl4.dev

deploy-production:
  stage: deploy
  image:
    name: hashicorp/terraform:latest
    entrypoint: [""]
  before_script:
    - apk add --no-cache curl helm
  script:
    - echo "ðŸš€ Deploying to production..."
    - cd infra/terraform/aws
    - terraform init
    - terraform apply -auto-approve
    - cd ../../..
    - helm upgrade --install x0tta6bl4 ./helm/x0tta6bl4 -f helm/x0tta6bl4/values-production.yaml
    - echo "Running health checks..."
    - ./scripts/health-check-production.sh
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      when: manual
  environment:
    name: production
    url: https://x0tta6bl4.dev
  when: manual  # Require manual approval for production
# ============================================
# WEST-0104: Anti-Delos Charter Test Suite
# ============================================

# Run all charter unit tests with coverage
test:charter:unit:
  stage: test
  script:
    - python -m pip install -q pytest pytest-asyncio pytest-cov
    - python -m pytest tests/test_charter_*.py -v --tb=short --junitxml=charter-junit.xml --cov=src/westworld --cov-report=xml --cov-report=term-missing
    - echo "Charter unit tests completed"
  artifacts:
    reports:
      junit: charter-junit.xml
    paths:
      - coverage.xml
    expire_in: 30 days
  allow_failure: false
  coverage: '/TOTAL.*\s+(\d+\.\d+)%/'

# Run charter integration tests
test:charter:integration:
  stage: test
  script:
    - python -m pip install -q pytest pytest-asyncio
    - python -m pytest tests/test_charter_integration.py tests/test_charter_async.py -v --tb=short
  allow_failure: false

# Run charter comprehensive tests
test:charter:comprehensive:
  stage: test
  script:
    - python -m pip install -q pytest
    - python -m pytest tests/test_charter_comprehensive.py tests/test_charter_edges.py -v --tb=short
  allow_failure: false
