# Гайд по адаптации промтов под разные модели

Этот файл содержит детальные рекомендации по созданию промтов для конкретных моделей. Информация собрана из официальной документации и должна дополняться актуальными данными из веб-исследования при каждом использовании скила.

## Claude (Anthropic)

### Структура промта
```
[System prompt с XML-тегами]

<role>Описание роли</role>

<context>
Фоновая информация
</context>

<instructions>
Пошаговые инструкции
</instructions>

<examples>
<example>
<input>Пример входа</input>
<output>Пример выхода</output>
</example>
</examples>

<output_format>
Требуемый формат ответа
</output_format>

<constraints>
Ограничения и правила
</constraints>
```

### Ключевые техники
- **XML-теги** — основной способ структурирования. Claude отлично понимает XML и использует его для парсинга секций
- **Позитивные инструкции** — "Отвечай кратко и по делу" лучше чем "Не пиши длинные ответы"
- **Prefill** — можно начать ответ assistant для направления формата: `{"role": "assistant", "content": "{"result":"}`
- **Extended thinking** — для сложных задач (аналитика, код, математика) активировать thinking mode
- **Примеры** — Claude отлично обучается через few-shot примеры внутри XML-тегов
- **Chain of thought** — запрашивать рассуждения внутри специального тега перед ответом

### Параметры
- temperature: 0.0-0.3 для точных задач, 0.7-1.0 для креативных
- max_tokens: зависит от задачи, Claude поддерживает длинные ответы
- Контекст: до 200K токенов (Opus/Sonnet)

### Антипаттерны для Claude
- Не использовать "Act as..." — Claude лучше реагирует на прямые инструкции
- Не перегружать негативными инструкциями
- Не дублировать одну инструкцию разными словами

---

## GPT (OpenAI)

### Структура промта
```json
{
  "model": "gpt-5",
  "messages": [
    {
      "role": "system",
      "content": "Системный промт с ролью, инструкциями и ограничениями"
    },
    {
      "role": "user", 
      "content": "Запрос пользователя с контекстом"
    }
  ]
}
```

### Ключевые техники
- **System message** — определяет поведение, тон и ограничения
- **Markdown структура** — GPT хорошо понимает заголовки, списки, блоки кода
- **Structured Outputs** — JSON Schema для гарантированного формата ответа
- **Function calling / Tools** — нативная поддержка вызова функций
- **"Let's think step by step"** — активирует chain-of-thought рассуждения
- **Few-shot в user/assistant парах** — примеры как отдельные сообщения

### Параметры
- temperature: 0 для детерминированных задач, 0.7-1.0 для креативных
- response_format: {"type": "json_schema", "json_schema": {...}} для structured outputs
- Контекст: зависит от версии модели

### Антипаттерны для GPT
- Не полагаться на system prompt как единственную защиту
- Не смешивать роль и инструкции без разделения
- Не игнорировать structured outputs когда нужен конкретный формат

---

## Gemini (Google)

### Структура промта
```
System instruction:
Роль, правила поведения, формат ответов

User prompt:
Конкретный запрос с контекстом
```

### Ключевые техники
- **System instructions** — отдельное поле для постоянных инструкций
- **Grounding** — подключение Google Search для актуальной информации
- **Мультимодальность** — нативная работа с изображениями, видео, аудио, PDF
- **JSON mode** — response_mime_type: "application/json" для структурированных ответов
- **Safety settings** — настройка порогов фильтрации контента
- **Code execution** — встроенное выполнение кода
- **Thinking mode** — для Gemini 2.5 доступен режим рассуждений

### Параметры
- temperature: 0-2.0 (расширенный диапазон)
- top_p, top_k: дополнительные параметры сэмплирования
- Контекст: до 1M+ токенов (модели с длинным контекстом)

### Антипаттерны для Gemini
- Не игнорировать мультимодальные возможности когда они уместны
- Не пропускать safety settings для production

---

## Llama (Meta)

### Структура промта
```
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

Системный промт<|eot_id|><|start_header_id|>user<|end_header_id|>

Запрос пользователя<|eot_id|><|start_header_id|>assistant<|end_header_id|>
```

**Примечание:** При использовании через API-провайдеров (Together, Fireworks, Groq) специальные токены подставляются автоматически — достаточно формата system/user/assistant.

### Ключевые техники
- **Более явные инструкции** — open-source модели требуют большей конкретики
- **Чёткие разделители** — между секциями промта
- **Простой язык** — избегать сложных вложенных конструкций
- **Ограничение длины** — инструкции короче и конкретнее
- **Tool use** — поддержка в новых версиях через JSON-формат

### Параметры
- temperature: 0.1-0.6 для точных задач (open-source модели более чувствительны)
- max_tokens: учитывать размер контекста конкретной версии
- repetition_penalty: рекомендуется 1.1-1.2 для избежания повторов

---

## DeepSeek

### Ключевые техники
- **System prompt** — поддерживается, аналогично GPT-формату
- **Reasoning mode (R1)** — для задач, требующих глубокого рассуждения
- **JSON output** — через инструкции в промте
- **Код** — особенно сильна в задачах программирования
- **Китайский/английский** — одинаково хорошо работает на обоих языках

---

## Mistral

### Ключевые техники
- **System/user формат** — стандартные роли
- **Function calling** — нативная поддержка
- **JSON mode** — через response_format
- **Concise prompting** — Mistral хорошо работает с краткими инструкциями
- **Guardrails** — встроенная система безопасности

---

## Grok (xAI)

### Ключевые техники
- **System instructions** — аналогично GPT/Claude
- **Real-time data** — доступ к актуальным данным через X
- **Reasoning mode** — для сложных задач
- **Менее формальный тон** — по умолчанию более разговорный

---

## Универсальные техники промтинга

### Role Prompting
Задание роли/экспертизы модели. Работает во всех моделях, но формулировка отличается:
- Claude: Прямое описание задачи без "Act as..."
- GPT: "You are a..." в system prompt
- Open-source: Максимально конкретное описание роли

### Few-Shot Examples
Примеры ожидаемого результата. Количество зависит от сложности:
- Простые задачи: 1-2 примера
- Средние: 3-5 примеров
- Сложные/неочевидные: 5+ примеров

### Chain-of-Thought (CoT)
Пошаговое рассуждение перед ответом:
- Явный: "Рассуждай пошагово перед ответом"
- Структурированный: Теги для рассуждений и ответа отдельно
- Zero-shot CoT: "Let's think step by step"

### Output Format Specification
Точное описание формата. Варианты по моделям:
- Claude: XML-теги для разметки секций ответа
- GPT: JSON Schema через structured outputs
- Gemini: response_mime_type для формата
- Open-source: Подробное описание + пример ожидаемого формата

### Constraint Setting
Явные правила и ограничения:
- Длина ответа
- Запрещённые действия
- Обработка неопределённости ("если не уверен — скажи об этом")
- Граничные случаи

### Self-Consistency / Verification
Просьба проверить свой ответ:
- "Проверь ответ на ошибки перед выдачей"
- "Если результат не соответствует критериям — исправь"
- Двухэтапная генерация: сначала черновик, потом финальная версия
