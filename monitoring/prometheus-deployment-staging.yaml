# Prometheus Deployment for Staging/Beta
# Дата: 2026-01-08
# Версия: 3.4.0-fixed2

---
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: 'x0tta6bl4-staging'
        environment: 'staging'
    
    # Alertmanager configuration
    alerting:
      alertmanagers:
        - static_configs:
            - targets:
                - 'alertmanager.monitoring.svc.cluster.local:9093'
    
    # Load alert rules
    rule_files:
      - '/etc/prometheus/alerts/*.yaml'
    
    # Scrape configurations
    scrape_configs:
      # x0tta6bl4 staging pods
      - job_name: 'x0tta6bl4-staging'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - x0tta6bl4-staging
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: x0tta6bl4.*
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
        metrics_path: '/metrics'
        scrape_interval: 15s
      
      # Prometheus itself
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-alerts
  namespace: monitoring
data:
  alerts-basic.yaml: |
    # Prometheus Alert Rules for x0tta6bl4 - Basic Setup (Beta)
    # Essential alerts for beta launch
    # Дата: 2026-01-08

    groups:
      - name: x0tta6bl4_basic_alerts
        interval: 30s
        rules:
          # Health Check Alerts (CRITICAL)
          - alert: X0TTA6BL4HealthCheckFailed
            expr: up{job="x0tta6bl4-staging"} == 0
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "x0tta6bl4 health check failed"
              description: "Service {{ $labels.instance }} is down for more than 2 minutes"

          # High Error Rate (WARNING)
          - alert: X0TTA6BL4HighErrorRate
            expr: rate(x0tta6bl4_errors_total[5m]) > 10
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High error rate detected"
              description: "Error rate is {{ $value }} errors/sec (threshold: 10/sec)"

          # High Latency (WARNING)
          - alert: X0TTA6BL4HighLatency
            expr: histogram_quantile(0.95, rate(x0tta6bl4_request_duration_seconds_bucket[5m])) > 1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High latency detected"
              description: "p95 latency is {{ $value }}s (threshold: 1s)"

          # PQC Handshake Failures (CRITICAL)
          - alert: X0TTA6BL4PQCHandshakeFailure
            expr: rate(x0tta6bl4_pqc_handshake_failures_total[5m]) > 0.1
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "High PQC handshake failure rate"
              description: "PQC handshake failure rate is {{ $value }} failures/sec"

          # High Memory Usage (WARNING)
          - alert: X0TTA6BL4HighMemoryUsage
            expr: container_memory_usage_bytes{pod=~"x0tta6bl4.*"} / container_spec_memory_limit_bytes > 0.9
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "High memory usage"
              description: "Memory usage is {{ $value | humanizePercentage }} (threshold: 90%)"

          # Frequent Pod Restarts (WARNING)
          - alert: X0TTA6BL4FrequentRestarts
            expr: rate(kube_pod_container_status_restarts_total{pod=~"x0tta6bl4.*"}[15m]) > 0
            for: 15m
            labels:
              severity: warning
            annotations:
              summary: "Frequent pod restarts"
              description: "Pod {{ $labels.pod }} is restarting frequently"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
        - name: prometheus
          image: prom/prometheus:v2.52.0
          args:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--web.enable-lifecycle'
            - '--web.console.libraries=/usr/share/prometheus/console_libraries'
            - '--web.console.templates=/usr/share/prometheus/consoles'
          ports:
            - name: web
              containerPort: 9090
          resources:
            requests:
              cpu: "300m"
              memory: "512Mi"
            limits:
              cpu: "800m"
              memory: "1Gi"
          volumeMounts:
            - name: config
              mountPath: /etc/prometheus
            - name: alerts
              mountPath: /etc/prometheus/alerts
            - name: data
              mountPath: /prometheus
      volumes:
        - name: config
          configMap:
            name: prometheus-config
        - name: alerts
          configMap:
            name: prometheus-alerts
        - name: data
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
spec:
  selector:
    app: prometheus
  ports:
    - port: 9090
      targetPort: 9090
      name: http
  type: ClusterIP

