"""
Ledger RAG Search Integration

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ RAG pipeline –¥–ª—è semantic search –≤ CONTINUITY.md
"""

import asyncio
import logging
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

from src.rag.chunker import ChunkingStrategy, DocumentChunker
from src.rag.pipeline import RAGPipeline, RAGResult
from src.storage.vector_index import VectorIndex

logger = logging.getLogger(__name__)

PROJECT_ROOT = Path(__file__).parent.parent.parent
CONTINUITY_FILE = PROJECT_ROOT / "CONTINUITY.md"


@dataclass
class LedgerSearchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –≤ ledger"""

    query: str
    results: List[Dict[str, Any]]
    total_results: int
    search_time_ms: float
    metadata: Dict[str, Any] = None


class LedgerRAGSearch:
    """
    Semantic search –≤ Continuity Ledger —á–µ—Ä–µ–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π RAG pipeline.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
    - RAGPipeline –¥–ª—è semantic search
    - VectorIndex (HNSW) –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    - DocumentChunker –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ chunks
    """

    def __init__(
        self,
        continuity_file: Path = CONTINUITY_FILE,
        vector_index: Optional[VectorIndex] = None,
        top_k: int = 10,
        enable_reranking: bool = True,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ledger RAG Search.

        Args:
            continuity_file: –ü—É—Ç—å –∫ CONTINUITY.md
            vector_index: VectorIndex instance (—Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π –µ—Å–ª–∏ None)
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
            enable_reranking: –í–∫–ª—é—á–∏—Ç—å re-ranking —á–µ—Ä–µ–∑ CrossEncoder
        """
        self.continuity_file = continuity_file
        self.top_k = top_k

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG pipeline —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
        self.rag = RAGPipeline(
            vector_index=vector_index, top_k=top_k, enable_reranking=enable_reranking
        )

        self._indexed = False
        logger.info(f"‚úÖ LedgerRAGSearch –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (file: {continuity_file})")

    def is_indexed(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω –ª–∏ ledger"""
        return self._indexed

    async def index_ledger(self, force: bool = False) -> bool:
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ CONTINUITY.md –≤ RAG pipeline.

        Args:
            force: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–∞–∂–µ –µ—Å–ª–∏ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        if self._indexed and not force:
            logger.info("‚úÖ Ledger —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω")
            return True

        if not self.continuity_file.exists():
            logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.continuity_file}")
            return False

        logger.info(f"üìñ –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ {self.continuity_file}...")

        try:
            content = self.continuity_file.read_text(encoding="utf-8")

            # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —Ä–∞–∑–¥–µ–ª—ã (–ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º ##)
            sections = self._parse_sections(content)

            logger.info(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(sections)}")

            # –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
            total_chunks = 0
            for i, section in enumerate(sections, 1):
                logger.info(
                    f"  [{i}/{len(sections)}] –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ: {section['title']}"
                )

                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª –≤ RAG
                chunk_ids = self.rag.add_document(
                    text=section["content"],
                    document_id=f"continuity_{section['title'].lower().replace(' ', '_').replace('/', '_')}",
                    metadata={
                        "title": section["title"],
                        "section": section["title"],
                        "source": "CONTINUITY.md",
                        "section_index": i,
                    },
                )

                total_chunks += len(chunk_ids)
                logger.info(f"     ‚úÖ –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ chunks: {len(chunk_ids)}")

            self._indexed = True
            logger.info(f"‚úÖ CONTINUITY.md —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω")
            logger.info(f"üìä –í—Å–µ–≥–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(sections)}, chunks: {total_chunks}")

            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}", exc_info=True)
            return False

    def _parse_sections(self, content: str) -> List[Dict[str, str]]:
        """
        –†–∞–∑–±–æ—Ä CONTINUITY.md –Ω–∞ —Ä–∞–∑–¥–µ–ª—ã.

        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–∞–∑–¥–µ–ª–æ–≤ —Å title –∏ content
        """
        sections = []
        current_section = []
        current_title = None

        for line in content.split("\n"):
            if line.startswith("## "):
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ä–∞–∑–¥–µ–ª
                if current_title and current_section:
                    sections.append(
                        {"title": current_title, "content": "\n".join(current_section)}
                    )
                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª
                current_title = line.replace("## ", "").strip()
                current_section = [line]
            else:
                current_section.append(line)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑–¥–µ–ª
        if current_title and current_section:
            sections.append(
                {"title": current_title, "content": "\n".join(current_section)}
            )

        return sections

    async def query(
        self, question: str, top_k: Optional[int] = None
    ) -> LedgerSearchResult:
        """
        Semantic search –≤ ledger —á–µ—Ä–µ–∑ RAG.

        Args:
            question: –í–æ–ø—Ä–æ—Å –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è self.top_k –µ—Å–ª–∏ None)

        Returns:
            LedgerSearchResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞
        """
        import time

        start_time = time.time()

        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ ledger –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω
        if not self._indexed:
            logger.warning("‚ö†Ô∏è Ledger –Ω–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω. –ò–Ω–¥–µ–∫—Å–∏—Ä—É—é...")
            await self.index_ledger()

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ RAG
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ retrieve (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π) —á–µ—Ä–µ–∑ asyncio
            rag_result = await asyncio.to_thread(
                self.rag.retrieve, question, top_k=top_k or self.top_k
            )

            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç LedgerSearchResult
            results = []
            for i, chunk in enumerate(rag_result.retrieved_chunks):
                # –ü–æ–ª—É—á–∞–µ–º score –∏–∑ —Å–ø–∏—Å–∫–∞ scores
                score = rag_result.scores[i] if i < len(rag_result.scores) else 0.0

                results.append(
                    {
                        "text": chunk.text,
                        "score": score,
                        "metadata": (
                            chunk.metadata if hasattr(chunk, "metadata") else {}
                        ),
                        "section": (
                            chunk.metadata.get("title", "Unknown")
                            if hasattr(chunk, "metadata") and chunk.metadata
                            else "Unknown"
                        ),
                    }
                )

            search_time_ms = (time.time() - start_time) * 1000

            return LedgerSearchResult(
                query=question,
                results=results,
                total_results=len(results),
                search_time_ms=search_time_ms,
                metadata={
                    "retrieval_time_ms": rag_result.retrieval_time_ms,
                    "rerank_time_ms": rag_result.rerank_time_ms,
                },
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}", exc_info=True)
            search_time_ms = (time.time() - start_time) * 1000
            return LedgerSearchResult(
                query=question,
                results=[],
                total_results=0,
                search_time_ms=search_time_ms,
                metadata={"error": str(e)},
            )

    async def search(self, query: str, top_k: Optional[int] = None) -> Dict[str, Any]:
        """
        –£–¥–æ–±–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞ (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict –≤–º–µ—Å—Ç–æ dataclass).

        Args:
            query: –í–æ–ø—Ä–æ—Å –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞
        """
        result = await self.query(query, top_k)
        return {
            "query": result.query,
            "results": result.results,
            "total_results": result.total_results,
            "search_time_ms": result.search_time_ms,
            "metadata": result.metadata,
        }


# Singleton instance –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ API
_ledger_rag_instance: Optional[LedgerRAGSearch] = None


def get_ledger_rag() -> LedgerRAGSearch:
    """–ü–æ–ª—É—á–∏—Ç—å singleton instance LedgerRAGSearch"""
    global _ledger_rag_instance
    if _ledger_rag_instance is None:
        _ledger_rag_instance = LedgerRAGSearch()
    return _ledger_rag_instance
