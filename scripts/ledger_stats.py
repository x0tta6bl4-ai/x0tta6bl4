#!/usr/bin/env python3
"""
–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ Continuity Ledger

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ ledger
"""

import re
import sys
from datetime import datetime
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent.parent
CONTINUITY_FILE = PROJECT_ROOT / "CONTINUITY.md"


def analyze_ledger():
    """–ê–Ω–∞–ª–∏–∑ CONTINUITY.md –∏ –≤—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    if not CONTINUITY_FILE.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {CONTINUITY_FILE}")
        sys.exit(1)

    content = CONTINUITY_FILE.read_text(encoding="utf-8")

    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_lines = len(content.splitlines())
    total_chars = len(content)
    total_words = len(content.split())

    # –†–∞–∑–¥–µ–ª—ã
    sections = re.findall(r"^##\s+(.+)$", content, re.MULTILINE)

    # –ü–æ–¥—Ä–∞–∑–¥–µ–ª—ã
    subsections = re.findall(r"^###\s+(.+)$", content, re.MULTILINE)

    # –°—Å—ã–ª–∫–∏
    links = re.findall(r"\[([^\]]+)\]\(([^\)]+)\)", content)

    # –ö–æ–¥ –±–ª–æ–∫–∏
    code_blocks = re.findall(r"```[\s\S]*?```", content)

    # UNCONFIRMED –º–µ—Ç–∫–∏
    unconfirmed = content.count("UNCONFIRMED")

    # TODO/FIXME
    todos = len(re.findall(r"(TODO|FIXME|XXX)", content, re.IGNORECASE))

    # –ú–µ—Ç—Ä–∏–∫–∏
    metrics = re.findall(r"(\d+\.?\d*)\s*(ms|s|%|MB|GB)", content, re.IGNORECASE)

    # –î–∞—Ç—ã
    dates = re.findall(r"\d{4}-\d{2}-\d{2}", content)

    print("=" * 60)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê CONTINUITY LEDGER")
    print("=" * 60)
    print(f"\nüìÑ –§–∞–π–ª: {CONTINUITY_FILE}")
    print(
        f"üìÖ –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {datetime.fromtimestamp(CONTINUITY_FILE.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')}"
    )

    print(f"\nüìè –†–∞–∑–º–µ—Ä:")
    print(f"  - –°—Ç—Ä–æ–∫: {total_lines:,}")
    print(f"  - –°–∏–º–≤–æ–ª–æ–≤: {total_chars:,}")
    print(f"  - –°–ª–æ–≤: {total_words:,}")
    print(f"  - –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {CONTINUITY_FILE.stat().st_size / 1024:.2f} KB")

    print(f"\nüìö –°—Ç—Ä—É–∫—Ç—É—Ä–∞:")
    print(f"  - –†–∞–∑–¥–µ–ª–æ–≤ (##): {len(sections)}")
    print(f"  - –ü–æ–¥—Ä–∞–∑–¥–µ–ª–æ–≤ (###): {len(subsections)}")
    print(f"  - –°—Å—ã–ª–æ–∫: {len(links)}")
    print(f"  - –ö–æ–¥ –±–ª–æ–∫–æ–≤: {len(code_blocks)}")

    print(f"\n‚ö†Ô∏è  –°—Ç–∞—Ç—É—Å:")
    print(f"  - UNCONFIRMED –º–µ—Ç–æ–∫: {unconfirmed}")
    print(f"  - TODO/FIXME: {todos}")

    print(f"\nüìà –ú–µ—Ç—Ä–∏–∫–∏:")
    print(f"  - –ù–∞–π–¥–µ–Ω–æ –º–µ—Ç—Ä–∏–∫: {len(metrics)}")
    if metrics:
        print(f"  - –ü—Ä–∏–º–µ—Ä—ã: {', '.join([f'{m[0]}{m[1]}' for m in metrics[:5]])}")

    print(f"\nüìÖ –î–∞—Ç—ã:")
    print(f"  - –£–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥–∞—Ç: {len(dates)}")
    if dates:
        unique_dates = sorted(set(dates))
        print(f"  - –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∞—Ç: {len(unique_dates)}")
        print(f"  - –ü–µ—Ä–≤–∞—è: {unique_dates[0]}")
        print(f"  - –ü–æ—Å–ª–µ–¥–Ω—è—è: {unique_dates[-1]}")

    # –¢–æ–ø —Ä–∞–∑–¥–µ–ª–æ–≤ –ø–æ —Ä–∞–∑–º–µ—Ä—É
    print(f"\nüìã –¢–æ–ø-10 —Ä–∞–∑–¥–µ–ª–æ–≤ –ø–æ —Ä–∞–∑–º–µ—Ä—É:")
    section_sizes = []
    current_section = None
    current_size = 0

    for line in content.splitlines():
        if line.startswith("## "):
            if current_section:
                section_sizes.append((current_section, current_size))
            current_section = line.replace("## ", "").strip()
            current_size = len(line)
        else:
            current_size += len(line) + 1  # +1 for newline

    if current_section:
        section_sizes.append((current_section, current_size))

    section_sizes.sort(key=lambda x: x[1], reverse=True)
    for i, (section, size) in enumerate(section_sizes[:10], 1):
        print(f"  {i}. {section[:50]}: {size:,} —Å–∏–º–≤–æ–ª–æ–≤")

    print("\n" + "=" * 60)


if __name__ == "__main__":
    analyze_ledger()
