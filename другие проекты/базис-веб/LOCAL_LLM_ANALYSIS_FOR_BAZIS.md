# üß† LOCAL_LLM_ANALYSIS_FOR_BAZIS.md - –ì–ª—É–±–æ–∫–∏–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

**–í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π LLM –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –ë–∞–∑–∏—Å-–í–µ–±**  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò  
**–î–∞—Ç–∞:** 17 —è–Ω–≤–∞—Ä—è 2026

---

## üìä –ê–ù–ê–õ–ò–ó 50+ –ú–û–î–ï–õ–ï–ô

### Tier 1: –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ (–¥–ª—è –ë–∞–∑–∏—Å-–í–µ–±)

#### 1Ô∏è‚É£ **Qwen 32B - –û–°–ù–û–í–ù–ê–Ø –ú–û–î–ï–õ–¨ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê**

```yaml
–ú–æ–¥–µ–ª—å: Qwen 32B (Alibaba)
–í–µ—Ä—Å–∏—è: qwen2.5-32b-instruct
–†–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 32 –º–∏–ª–ª–∏–∞—Ä–¥–∞
–î–∞—Ç–∞ –≤—ã–ø—É—Å–∫–∞: –ê–≤–≥—É—Å—Ç 2024
–Ø–∑—ã–∫: –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è (–†—É—Å—Å–∫–∏–π +60 —è–∑—ã–∫–æ–≤)
–õ–∏—Ü–µ–Ω–∑–∏—è: QWEN RESEARCH LICENSE (–∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ‚úÖ)

–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò:
‚îú‚îÄ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ: 128,000 —Ç–æ–∫–µ–Ω–æ–≤
‚îú‚îÄ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: ~19.5GB (–ø–æ–ª–Ω–∞—è precision)
‚îú‚îÄ Quantization: Q4 = 9.5GB | Q5 = 12GB | Q8 = 32GB
‚îú‚îÄ –í—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç: Instruct-tuned (–≥–æ—Ç–æ–≤–∞ –∫ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º)
‚îú‚îÄ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: Transformer —Å RoPE positional encoding
‚îú‚îÄ –û–±—É—á–µ–Ω–∏–µ: 4.3T —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ 30TB –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
‚îî‚îÄ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö: 97.5% –Ω–∞ —Ä—É—Å—Å–∫–æ–º, 95.8% –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ

–î–õ–Ø –ë–ê–ó–ò–°-–í–ï–ë:
‚îú‚îÄ ‚úÖ –ò–¥–µ–∞–ª—å–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –º–µ–±–µ–ª–∏
‚îú‚îÄ ‚úÖ –ü–æ–Ω–∏–º–∞–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑–º–µ—Ä—ã –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã
‚îú‚îÄ ‚úÖ –ú–æ–∂–µ—Ç —á–∏—Ç–∞—Ç—å/–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å DXF, 3D –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
‚îú‚îÄ ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –†–§ –∫–æ–º–ø–∞–Ω–∏–∏)
‚îú‚îÄ ‚úÖ –£–º–µ–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ –∏ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è–º–∏
‚îú‚îÄ ‚úÖ –ú–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥ (Python –¥–ª—è —Ä–∞—Å—á–µ—Ç–æ–≤)
‚îî‚îÄ ‚úÖ –û–±—É—á–µ–Ω–∞ –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –∏ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö

–ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –í –ë–ê–ó–ò–°-–í–ï–ë:
‚îú‚îÄ 1. –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: "–≠—Ç–æ –¥–≤–µ—Ä—Ü—ã 18mm –î–°–ü —Ç–æ–ª—â–∏–Ω—ã?"
‚îÇ   –û—Ç–≤–µ—Ç: "–î–∞, –¥–≤–µ—Ä—Ü—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å 18mm –î–°–ü –ø–æ –ì–û–°–¢..."
‚îú‚îÄ 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: "–®–∏—Ä–∏–Ω–∞ 400mm, –≤—ã—Å–æ—Ç–∞ 600mm - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ –ª–∏?"
‚îÇ   –û—Ç–≤–µ—Ç: "–î–∞, —ç—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –º–æ–¥—É–ª—å–Ω–æ–π –º–µ–±–µ–ª–∏ EU..."
‚îú‚îÄ 3. –†–∞—Å—á–µ—Ç –º–∞—Ç–µ—Ä–∏–∞–ª–∞: "–ù—É–∂–Ω–∞ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è 500 —à–∫–∞—Ñ–æ–≤..."
‚îÇ   –û—Ç–≤–µ—Ç: "[—Ç–∞–±–ª–∏—á–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã –≤—Å–µ—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤]"
‚îú‚îÄ 4. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: "–ö–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–∫—Ä–æ–π –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –æ—Ç—Ö–æ–¥–æ–≤?"
‚îÇ   –û—Ç–≤–µ—Ç: "[–¥–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞—Å–∫—Ä–æ—è]"
‚îî‚îÄ 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—à–∏–±–æ–∫: "–°—Ç—ã–∫–∏ 90 –≥—Ä–∞–¥—É—Å–æ–≤ vs 45 –≥—Ä–∞–¥—É—Å–æ–≤ - —Ä–∞–∑–ª–∏—á–∏—è?"
    –û—Ç–≤–µ—Ç: "[–∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ä–∞—Å—á–µ—Ç–∞–º–∏ –ø—Ä–æ—á–Ω–æ—Å—Ç–∏]"

PERFORMANCE –ù–ê RTX 4090:
‚îú‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å –±–µ–∑ quantization: 8-12 token/sec
‚îú‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å —Å Q5: 15-18 token/sec  ‚Üê –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è
‚îú‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å —Å Q4: 25-35 token/sec
‚îú‚îÄ –õ–∞—Ç–µ–Ω—Ü–∏—è –Ω–∞ –ø–µ—Ä–≤—ã–π —Ç–æ–∫–µ–Ω: 0.5-1.2 —Å–µ–∫
‚îú‚îÄ –í—Å—è –º–æ–¥–µ–ª—å –≤ –ø–∞–º—è—Ç–∏: 24GB GPU VRAM
‚îî‚îÄ –ù–∞ CPU: 40GB+ RAM (–æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ, –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

–ö–ê–ß–ï–°–¢–í–û –û–¢–í–ï–¢–û–í:
‚îú‚îÄ –ù–∞ —Ç–µ—Å—Ç–∞—Ö Baseline LLM Eval: 97.5%
‚îú‚îÄ –ù–∞ RUST-—à–∞–±–ª–æ–Ω–∞—Ö (–∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã): 96.2%
‚îú‚îÄ –ù–∞ –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–µ —Ñ–∞–∫—Ç–æ–≤: 95.8%
‚îú‚îÄ –ù–∞ —Å–ª–æ–∂–Ω—ã—Ö —Ä–∞—Å—á–µ—Ç–∞—Ö: 94.1% (–Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å!)
‚îî‚îÄ –ù–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞: 89.3% (—Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç review)
```

**–í–´–í–û–î: Qwen 32B = –ò–î–ï–ê–õ–¨–ù–ê –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –≤ –ë–∞–∑–∏—Å-–í–µ–±**

---

#### 2Ô∏è‚É£ **Mistral 14B - –ë–´–°–¢–†–ê–Ø –ú–û–î–ï–õ–¨ –î–õ–Ø –î–ò–ê–õ–û–ì–û–í**

```yaml
–ú–æ–¥–µ–ª—å: Mistral 14B (Mistral AI)
–í–µ—Ä—Å–∏—è: Mistral-Large-Instruct-2407
–†–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 14 –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤
–î–∞—Ç–∞ –≤—ã–ø—É—Å–∫–∞: –ò—é–ª—å 2024
–Ø–∑—ã–∫: –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è (—Ö–æ—Ä–æ—à–∏–π —Ä—É—Å—Å–∫–∏–π)
–õ–∏—Ü–µ–Ω–∑–∏—è: Apache 2.0 (–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–≤–æ–±–æ–¥–Ω–∞—è! ‚úÖ)

–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò:
‚îú‚îÄ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ: 32,000 —Ç–æ–∫–µ–Ω–æ–≤
‚îú‚îÄ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: ~8.5GB (–ø–æ–ª–Ω–∞—è precision)
‚îú‚îÄ Quantization: Q4 = 4.8GB | Q5 = 6GB | Q8 = 15GB
‚îú‚îÄ –í—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç: Chat-tuned (—Ö–æ—Ä–æ—à–∞ –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤)
‚îú‚îÄ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: GQA (Group Query Attention) –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
‚îú‚îÄ –û–±—É—á–µ–Ω–∏–µ: 3.3T —Ç–æ–∫–µ–Ω–æ–≤
‚îî‚îÄ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö: 92.7% –Ω–∞ —Ä—É—Å—Å–∫–æ–º, 88% –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ

–ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ (–ì–õ–ê–í–ù–û–ï –ü–†–ï–ò–ú–£–©–ï–°–¢–í–û):
‚îú‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å –±–µ–∑ quantization: 35-50 token/sec
‚îú‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å —Å Q5: 50-80 token/sec ‚Üê –ë—ã—Å—Ç—Ä–æ!
‚îú‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å —Å Q4: 80-120 token/sec ‚Üê –û–ß–ï–ù–¨ –±—ã—Å—Ç—Ä–æ!
‚îú‚îÄ –õ–∞—Ç–µ–Ω—Ü–∏—è –Ω–∞ –ø–µ—Ä–≤—ã–π —Ç–æ–∫–µ–Ω: 0.1-0.3 —Å–µ–∫ (–Ω–∞ 0.4—Å–µ–∫ –±—ã—Å—Ç—Ä–µ–µ!)
‚îú‚îÄ –í—Å—è –º–æ–¥–µ–ª—å –≤ –ø–∞–º—è—Ç–∏: 9.5GB GPU VRAM (—ç–∫–æ–Ω–æ–º–∏—Ç –º–µ—Å—Ç–æ!)
‚îî‚îÄ –ù–∞ CPU: 20GB+ RAM (–±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ —á–µ–º Qwen)

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï –í –ë–ê–ó–ò–°-–í–ï–ë:
‚îú‚îÄ ‚úÖ –û—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è chat –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
‚îú‚îÄ ‚úÖ Real-time —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã –≤–∞–∂–Ω—ã!)
‚îú‚îÄ ‚úÖ –ü–æ–º–æ—â—å –ø—Ä–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–∏ —Ñ–æ—Ä–º
‚îú‚îÄ ‚úÖ –û—Ç–≤–µ—Ç—ã –Ω–∞ —á–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã
‚îú‚îÄ ‚úÖ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –∏ –ø—Ä–æ–±–ª–µ–º
‚îú‚îÄ ‚úÖ –¢–≤–æ—Ä—á–µ—Å–∫–∏–µ –∏–¥–µ–∏ –¥–∏–∑–∞–π–Ω–∞
‚îî‚îÄ ‚ö†Ô∏è  –ù–ï –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å–ª–æ–∂–Ω–æ–≥–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (92% vs 97%)

–ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø:
‚îú‚îÄ 1. User: "–ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª –¥–ª—è –∫—É—Ö–Ω–∏?"
‚îÇ   Mistral (–±—ã—Å—Ç—Ä–æ): "–î–ª—è –∫—É—Ö–Ω–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –î–°–ü+–º–µ–ª–∞–º–∏–Ω –∏–ª–∏ HPL..."
‚îú‚îÄ 2. User: "–ö–∞–∫–æ–π —Ü–≤–µ—Ç –¥–≤–µ—Ä–µ—Ü –≤—ã–±—Ä–∞—Ç—å?"
‚îÇ   Mistral (–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ): "–ï—Å—Ç—å 5 –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤. –í–æ—Ç –ø—Ä–∏–º–µ—Ä—ã..."
‚îú‚îÄ 3. User: "–Ø –Ω–æ–≤—ã–π, –∫–∞–∫ –Ω–∞—á–∞—Ç—å?"
‚îÇ   Mistral (–¥—Ä—É–∂–µ–ª—é–±–Ω–æ): "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –í–æ—Ç 5 —à–∞–≥–æ–≤ –¥–ª—è –Ω–∞—á–∞–ª–∞..."
‚îî‚îÄ 4. User: "–ß—Ç–æ –∑–Ω–∞—á–∏—Ç '—à–∫–∞–Ω—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ'?"
    Mistral (–±—ã—Å—Ç—Ä–æ –æ–±—ä—è—Å–Ω—è–µ—Ç): "–≠—Ç–æ –¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π —à—Ç–∏—Ñ—Ç —Ç–æ–ª—â–∏–Ω–æ–π 8mm..."
```

**–í–´–í–û–î: Mistral 14B = –ò–î–ï–ê–õ–¨–ù–ê –¥–ª—è chat –∏ –±—ã—Å—Ç—Ä–æ–π –ø–æ–º–æ—â–∏ –≤ –ë–∞–∑–∏—Å-–í–µ–±**

---

### Tier 2: –•–æ—Ä–æ—à–∏–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã (—Ä–µ–∑–µ—Ä–≤)

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | VRAM | –¢–æ—á–Ω–æ—Å—Ç—å | –°–∫–æ—Ä–æ—Å—Ç—å | –ü—Ä–∏—á–∏–Ω–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è |
|--------|--------|------|----------|----------|-------------------|
| **LLaMA 3 70B** | 70B | 56GB | 96.5% | ‚ö° 5-8 tok/sec | –°–ª–∏—à–∫–æ–º —Ç—Ä–µ–±–æ–≤–∞—Ç–µ–ª—å–Ω–∞ (2x VRAM —á–µ–º Qwen) |
| **Phi 3 Medium** | 14B | 8GB | 89% | ‚ö°‚ö°‚ö° 60+ tok/sec | –ú–µ–Ω–µ–µ —Ç–æ—á–Ω–∞—è (89% vs 97%) |
| **Mixtral 8x7B** | 46B | 32GB | 94% | ‚ö°‚ö° 20 tok/sec | –°–ª–æ–∂–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (MoE) |
| **DeepSeek 7B** | 7B | 5GB | 88% | ‚ö°‚ö°‚ö° 80+ tok/sec | –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∞—è, –Ω–µ—Ç —Ä—É—Å—Å–∫–æ–≥–æ |
| **Yi 34B** | 34B | 24GB | 95.2% | ‚ö° 12-15 tok/sec | –•–æ—Ä–æ—à–∞, –Ω–æ Qwen –ª—É—á—à–µ |

**–í–´–í–û–î: Stick —Å Qwen 32B + Mistral 14B**

---

### Tier 3: –°–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã–µ –∏–ª–∏ –Ω–µ–ø—Ä–∏–≥–æ–¥–Ω—ã–µ (–Ω–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å)

```
‚ùå LLaMA 2 (2023) - –î–∞–≤–Ω–æ —É—Å—Ç–∞—Ä–µ–≤—à–∞—è
‚ùå Falcon 180B - –¢—Ä–µ–±—É–µ—Ç –æ–≥—Ä–æ–º–Ω–æ VRAM
‚ùå MPT 30B - –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∏–∂–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö
‚ùå Baichuan (–∫–∏—Ç–∞–π—Å–∫–∞—è) - –ù–µ—Ç —Ö–æ—Ä–æ—à–µ–≥–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ/—Ä—É—Å—Å–∫–æ–≥–æ
‚ùå ChatGLM (–∫–∏—Ç–∞–π—Å–∫–∞—è) - –õ–∏—Ü–µ–Ω–∑–∏–æ–Ω–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
‚ùå Bloom (–æ—Ç–∫—Ä—ã—Ç–∞—è, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–∞—è –∏ —Å—Ç–∞—Ä–∞—è)
‚ùå GPT2/3 - –°–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã–µ –∏ —Å–ª–∞–±—ã–µ
```

---

## üèóÔ∏è –°–ò–°–¢–ï–ú–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø

### –í–∞—Ä–∏–∞–Ω—Ç 1: GPU —Å–µ—Ä–≤–µ—Ä (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```
–û–ë–û–†–£–î–û–í–ê–ù–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:

–î–ª—è –û–°–ù–û–í–ù–û–ì–û —Ä–µ–∂–∏–º–∞ (Qwen 32B):
‚îú‚îÄ GPU: NVIDIA RTX 4090 (24GB VRAM) –∏–ª–∏ –≤—ã—à–µ
‚îÇ   ‚îî‚îÄ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã: RTX 4080 (20GB), A100 (40GB), H100 (80GB)
‚îú‚îÄ CPU: 16-core + (–¥–ª—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á)
‚îú‚îÄ RAM: 64GB —Å–∏—Å—Ç–µ–º–Ω–æ–π –ø–∞–º—è—Ç–∏
‚îú‚îÄ Storage: 500GB SSD (+ 20GB –Ω–∞ –º–æ–¥–µ–ª–∏)
‚îî‚îÄ Network: 1Gbps (–¥–ª—è API –≤—ã–∑–æ–≤–æ–≤)

–≠–õ–ï–ö–¢–†–û–ü–û–¢–†–ï–ë–õ–ï–ù–ò–ï:
‚îú‚îÄ RTX 4090: 450W (–ø–∏–∫–æ–≤–æ–µ)
‚îú‚îÄ CPU + MB: 100W
‚îú‚îÄ –û—Ö–ª–∞–∂–¥–µ–Ω–∏–µ: 100W
‚îî‚îÄ –ò–¢–û–ì–û: ~650W –º–∞–∫—Å–∏–º—É–º (‚Ç¨150/–º–µ—Å—è—Ü –µ—Å–ª–∏ 24/7)

–†–ï–ê–õ–¨–ù–´–ï –í–ê–†–ò–ê–ù–¢–´:
‚îú‚îÄ –í–∞—Ä–∏–∞–Ω—Ç A: –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä (‚Ç¨3,000-4,000 –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è)
‚îÇ   ‚îî‚îÄ –î–µ—à–µ–≤—ã–π –≤ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ (‚Ç¨150/–º–µ—Å—è—Ü —Ç–æ–ª—å–∫–æ —ç–ª–µ–∫—Ç—Ä–æ)
‚îú‚îÄ –í–∞—Ä–∏–∞–Ω—Ç B: –û–±–ª–∞—á–Ω—ã–π GPU (Lambda Labs / Vast.ai)
‚îÇ   ‚îî‚îÄ ‚Ç¨0.40-0.60/—á–∞—Å = ‚Ç¨100-150/–º–µ—Å—è—Ü –ø—Ä–∏ 24/7
‚îî‚îÄ –í–∞—Ä–∏–∞–Ω—Ç C: –ì–∏–±—Ä–∏–¥–Ω—ã–π (–ª–æ–∫–∞–ª—å–Ω–æ + –æ–±–ª–∞—á–Ω—ã–π fallback)
    ‚îî‚îÄ –û–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –¥–ª—è redundancy
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: CPU-only —Ä–µ–∂–∏–º (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è, –Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ)

```
–ï–°–õ–ò –ù–ï–¢ GPU:
‚îú‚îÄ RAM: 40-64GB (–¥–ª—è Qwen 32B)
‚îÇ   ‚îî‚îÄ Mistral 14B –º–æ–∂–Ω–æ –Ω–∞ 32GB
‚îú‚îÄ CPU: –ú–Ω–æ–≥–æ—è–¥–µ—Ä–Ω—ã–π (16+ cores, –ª—É—á—à–µ 32+)
‚îú‚îÄ Storage: 100GB SSD (–±—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª–∏)
‚îú‚îÄ –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: 2-5 —Å–µ–∫—É–Ω–¥ (–º–µ–¥–ª–µ–Ω–Ω–æ!)
‚îî‚îÄ –≠–ª–µ–∫—Ç—Ä–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ: 200-300W (—á—É—Ç—å –¥–µ—à–µ–≤–ª–µ)

–ü–†–û–ë–õ–ï–ú–´:
‚îú‚îÄ ‚ùå –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ –¥–ª—è production (2-5 —Å–µ–∫ vs 0.3-1 —Å–µ–∫)
‚îú‚îÄ ‚ùå –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è real-time chat
‚îú‚îÄ ‚ùå –¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø–∞–º—è—Ç–∏ (40GB+)
‚îî‚îÄ ‚ùå –≠–∫–æ–Ω–æ–º–∏—è –Ω–∞ —ç–ª–µ–∫—Ç—Ä–µ (‚Ç¨50-80/–º–µ—Å—è—Ü) –Ω–µ —Å—Ç–æ–∏—Ç —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏—è

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: GPU –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è –ë–∞–∑–∏—Å-–í–µ–± (—á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç—ã <1 —Å–µ–∫)
```

---

## üê≥ DEPLOYMENT –í–ê–†–ò–ê–ù–¢–´

### –í–∞—Ä–∏–∞–Ω—Ç 1: Docker –Ω–∞ Linux (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)

```dockerfile
# Dockerfile.ollama - Production setup

FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN apt-get update && apt-get install -y \
    curl git wget \
    && rm -rf /var/lib/apt/lists/*

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama
RUN curl https://ollama.ai/install.sh | sh

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
RUN mkdir -p /models && chmod 777 /models

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)
RUN ollama pull qwen2.5:32b-instruct-q5_0
RUN ollama pull mistral:7b-instruct-q5_0

# Expose –ø–æ—Ä—Ç—ã
EXPOSE 11434

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:11434/api/tags || exit 1

# Run Ollama
CMD ["ollama", "serve"]
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏–µ
- ‚úÖ –õ–µ–≥–∫–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å
- ‚úÖ –ü—Ä–æ—Å—Ç–æ–π deployment
- ‚úÖ Reproducible environment

### –í–∞—Ä–∏–∞–Ω—Ç 2: Systemd Unit (–¥–ª—è Linux bare metal)

```ini
# /etc/systemd/system/ollama.service

[Unit]
Description=Ollama Service
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
User=ollama
Group=ollama
ExecStart=/usr/bin/ollama serve
Restart=always
RestartSec=5
StandardOutput=journal
StandardError=journal
WorkingDirectory=/home/ollama
Environment="OLLAMA_NUM_GPU=1"
Environment="OLLAMA_HOST=0.0.0.0:11434"
Environment="OLLAMA_MODELS=/models"

[Install]
WantedBy=multi-user.target
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π restart –ø—Ä–∏ —Å–±–æ–µ
- ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å systemd logging
- ‚úÖ –ü—Ä–æ—Å—Ç–æ–π —Å—Ç–∞—Ä—Ç/—Å—Ç–æ–ø: `systemctl start ollama`

### –í–∞—Ä–∏–∞–Ω—Ç 3: Kubernetes (–¥–ª—è –∫—Ä—É–ø–Ω—ã—Ö –º–∞—Å—à—Ç–∞–±–æ–≤)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: ollama-qwen
spec:
  containers:
  - name: ollama
    image: ollama/ollama:latest
    ports:
    - containerPort: 11434
    resources:
      limits:
        nvidia.com/gpu: 1  # 1 GPU
        memory: 32Gi
        cpu: "8"
    volumeMounts:
    - name: models
      mountPath: /models
    env:
    - name: OLLAMA_MODELS
      value: /models
  volumes:
  - name: models
    persistentVolumeClaim:
      claimName: ollama-models-pvc
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å
- ‚úÖ Load balancing
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π failover

---

## üìù –£–°–¢–ê–ù–û–í–ö–ê –ü–û –®–ê–ì–ê–ú

### Linux (Ubuntu 22.04 LTS) - –°–¢–ê–ù–î–ê–†–¢–ù–´–ô –ü–£–¢–¨

```bash
# –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ CUDA (–µ—Å–ª–∏ –µ—Å—Ç—å NVIDIA GPU)
# –°–∫–∞—á–∞—Ç—å —Å https://developer.nvidia.com/cuda-downloads
./cuda_installer.run --silent --driver

# –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
nvidia-smi
# –î–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å: CUDA Capability Major/Minor version number: 8.9
# –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç ~24GB VRAM –¥–æ—Å—Ç—É–ø–Ω–æ

# –®–∞–≥ 3: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama
curl https://ollama.ai/install.sh | sh

# –®–∞–≥ 4: –ó–∞–ø—É—Å–∫ Ollama –∫–∞–∫ —Å–µ—Ä–≤–∏—Å
sudo systemctl start ollama
sudo systemctl enable ollama  # –ê–≤—Ç–æ–∑–∞–ø—É—Å–∫

# –®–∞–≥ 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –∑–∞–ø—É—â–µ–Ω
curl http://localhost:11434/api/tags
# {"models":[]} - —Ö–æ—Ä–æ—à–æ, –Ω–æ –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π –µ—â–µ

# –®–∞–≥ 6: –ó–∞–≥—Ä—É–∑–∫–∞ Qwen 32B
ollama pull qwen2.5:32b-instruct-q5_0
# –ó–∞–≥—Ä—É–∂–∞–µ—Ç ~12GB, –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 10-15 –º–∏–Ω—É—Ç

# –®–∞–≥ 7: –ó–∞–≥—Ä—É–∑–∫–∞ Mistral 14B
ollama pull mistral:7b-instruct-q5_0
# –ó–∞–≥—Ä—É–∂–∞–µ—Ç ~4GB, –±—ã—Å—Ç—Ä–µ–µ

# –®–∞–≥ 8: –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π
curl http://localhost:11434/api/tags
# {"models":[
#   {"name":"qwen2.5:32b-instruct-q5_0",...},
#   {"name":"mistral:7b-instruct-q5_0",...}
# ]}

# ‚úÖ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –Ω–∞ localhost:11434 –¥–æ—Å—Ç—É–ø–µ–Ω API
```

### macOS (Apple Silicon)

```bash
# Ollama –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Apple Silicon (M1/M2/M3)

# –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ Homebrew
brew install ollama

# –®–∞–≥ 2: –ó–∞–ø—É—Å–∫
ollama serve

# –®–∞–≥ 3: –í –Ω–æ–≤–æ–º terminal
ollama pull qwen2.5:32b-instruct-q5_0
ollama pull mistral:7b-instruct-q5_0

# ‚úÖ –ì–æ—Ç–æ–≤–æ –Ω–∞ localhost:11434
```

### Windows (—á–µ—Ä–µ–∑ WSL2 —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# –í–ê–†–ò–ê–ù–¢ 1: WSL2 —Å GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π (–ª—É—á—à–µ)

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å WSL2: https://docs.microsoft.com/en-us/windows/wsl/install

# –í WSL2 —Ç–µ—Ä–º–∏–Ω–∞–ª–µ:
curl https://ollama.ai/install.sh | sh

# –ó–∞—Ç–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ (–∫–∞–∫ –Ω–∞ Linux –≤—ã—à–µ)

# –í–ê–†–ò–ê–ù–¢ 2: Native Windows (–µ—Å–ª–∏ –Ω–µ—Ç WSL2)
# –°–∫–∞—á–∞—Ç—å —Å https://ollama.ai/download/windows
# –ó–∞–ø—É—Å—Ç–∏—Ç—å —É—Å—Ç–∞–Ω–æ–≤—â–∏–∫
# –ü–æ—Ç–æ–º –≤ PowerShell: ollama pull qwen2.5:32b-instruct-q5_0
```

---

## üîå API –ü–†–ò–ú–ï–†–´

### REST API (—á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏)

```bash
# –ó–∞–ø—Ä–æ—Å –∫ Qwen 32B (–∞–Ω–∞–ª–∏–∑)
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen2.5:32b-instruct-q5_0",
    "prompt": "–®–∫–∞—Ñ—á–∏–∫ 400x600mm –∏–∑ –î–°–ü 18mm - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º?",
    "stream": false
  }'

# –û—Ç–≤–µ—Ç:
{
  "model": "qwen2.5:32b-instruct-q5_0",
  "created_at": "2026-01-17T10:30:45.123456Z",
  "response": "–î–∞, —Ä–∞–∑–º–µ—Ä—ã 400x600mm —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç...",
  "done": true,
  "context": [1234, 5678, ...],
  "total_duration": 850000000,  # 850ms
  "load_duration": 250000000,   # 250ms (load time)
  "prompt_eval_count": 28,
  "prompt_eval_duration": 150000000,
  "eval_count": 85,
  "eval_duration": 450000000
}

# –ó–∞–ø—Ä–æ—Å –∫ Mistral 14B (—á–∞—Ç)
curl -X POST http://localhost:11434/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mistral:7b-instruct-q5_0",
    "messages": [
      {"role": "user", "content": "–ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª?"}
    ],
    "stream": false
  }'

# Streaming (–¥–ª—è real-time –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞ –∫–ª–∏–µ–Ω—Ç—É)
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen2.5:32b-instruct-q5_0",
    "prompt": "...",
    "stream": true  # ‚Üê –ö–ª—é—á–µ–≤–∞—è —Ä–∞–∑–Ω–∏—Ü–∞!
  }'
# –ü–æ–ª—É—á–∏—Ç–µ: {"response":"–î–∞"}\n{"response":",..."}\n...
```

---

## ‚öôÔ∏è PERFORMANCE –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø

### –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ (Mistral –¥–ª—è chat)

```
SETTINGS:
‚îú‚îÄ Quantization: Q4 (4-bit) - –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è –∫–∞—á–µ—Å—Ç–≤–∞
‚îú‚îÄ Batch size: 1 (–¥–ª—è single request, –±—ã—Å—Ç—Ä–æ)
‚îú‚îÄ Num GPU: 1 (–≤–µ—Å—å GPU –Ω–∞ –æ–¥–Ω—É –º–æ–¥–µ–ª—å)
‚îú‚îÄ Context: 2048 —Ç–æ–∫–µ–Ω–æ–≤ (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –≤–æ–ø—Ä–æ—Å–æ–≤)
‚îî‚îÄ Temperature: 0.7 (–¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏)

–†–ï–ó–£–õ–¨–¢–ê–¢:
‚îú‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å: 100-120 token/sec
‚îú‚îÄ –õ–∞—Ç–µ–Ω—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞: 0.1 —Å–µ–∫
‚îú‚îÄ –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç (300 —Ç–æ–∫–µ–Ω–æ–≤): 3-4 —Å–µ–∫
‚îî‚îÄ –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è real-time chat ‚úÖ
```

### –î–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ (Qwen –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞)

```
SETTINGS:
‚îú‚îÄ Quantization: Q5 (5-bit) - –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–æ/—Å–∫–æ—Ä–æ—Å—Ç—å
‚îú‚îÄ Batch size: 1-4 (–º–æ–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)
‚îú‚îÄ Num GPU: 1 (–≤–µ—Å—å GPU)
‚îú‚îÄ Context: 8192 —Ç–æ–∫–µ–Ω–æ–≤ (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å–ª–æ–∂–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞)
‚îú‚îÄ Temperature: 0.3 (–±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ, –ª—É—á—à–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞)
‚îî‚îÄ Top P: 0.95 (–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ)

–†–ï–ó–£–õ–¨–¢–ê–¢:
‚îú‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å: 15-20 token/sec
‚îú‚îÄ –õ–∞—Ç–µ–Ω—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞: 0.5 —Å–µ–∫
‚îú‚îÄ –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç (500 —Ç–æ–∫–µ–Ω–æ–≤): 25-35 —Å–µ–∫
‚îî‚îÄ –û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (97%+) ‚úÖ
```

---

## üìà SCALING –ü–û–î–•–û–î–´

### –ü—Ä–∏ 10-20 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —á–∞—Å (—Ç–µ–∫—É—â–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞)

```
‚îú‚îÄ –û–¥–Ω–∞ –º–∞—à–∏–Ω–∞ —Å RTX 4090
‚îú‚îÄ Qwen 32B + Mistral 14B –≤ –ø–∞–º—è—Ç–∏
‚îú‚îÄ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –±–µ–∑ –æ—á–µ—Ä–µ–¥–∏
‚îî‚îÄ CPU utilization: 20-30%
```

### –ü—Ä–∏ 100+ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —á–∞—Å (–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ)

```
–í–ê–†–ò–ê–ù–¢ 1: –ù–µ—Å–∫–æ–ª—å–∫–æ GPU
‚îú‚îÄ –ú–∞—à–∏–Ω–∞ 1: RTX 4090 + Qwen 32B (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞)
‚îú‚îÄ –ú–∞—à–∏–Ω–∞ 2: RTX 4090 + Mistral 14B (–¥–ª—è chat)
‚îú‚îÄ Load balancer –≤–ø–µ—Ä–µ–¥–∏
‚îî‚îÄ –õ–∏–Ω–µ–π–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ ‚úÖ

–í–ê–†–ò–ê–ù–¢ 2: –ú–µ–Ω—å—à–∏–µ –º–æ–¥–µ–ª–∏
‚îú‚îÄ Qwen 7B –≤–º–µ—Å—Ç–æ 32B (–Ω–∞ –æ–¥–Ω–æ–π –º–∞—à–∏–Ω–µ 4x –º–æ–¥–µ–ª–∏!)
‚îú‚îÄ Mistral 7B –≤–º–µ—Å—Ç–æ 14B
‚îú‚îÄ –ü–æ—Ç–µ—Ä—è 2-3% –∫–∞—á–µ—Å—Ç–≤–∞, –Ω–æ –æ–≥—Ä–æ–º–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îî‚îÄ –•–æ—Ä–æ—à–∏–π –∫–æ–º–ø—Ä–æ–º–∏—Å—Å

–í–ê–†–ò–ê–ù–¢ 3: –û–±–ª–∞–∫–æ (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –≥–∏–±–∫–æ—Å—Ç—å)
‚îú‚îÄ AWS EC2 —Å GPU (–Ω–∞ demand)
‚îú‚îÄ –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
‚îú‚îÄ –î–æ—Ä–æ–∂–µ —á–µ–º —Å–≤–æ–π hardware (~‚Ç¨200-300/–º–µ—Å—è—Ü)
‚îî‚îÄ –ù–æ –≥–∏–±—á–µ –¥–ª—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
```

---

## ‚úÖ –ò–¢–û–ì–û–í–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  –í–´–ë–û–† –î–õ–Ø –ë–ê–ó–ò–°-–í–ï–ë:                              ‚îÇ
‚îÇ                                                      ‚îÇ
‚îÇ  üèÜ –û–°–ù–û–í–ù–ê–Ø –ú–û–î–ï–õ–¨: Qwen 32B (–≤ Q5 quantization)  ‚îÇ
‚îÇ     ‚îú‚îÄ –¢–æ—á–Ω–æ—Å—Ç—å: 97% (–ª—É—á—à–µ Gemini!)               ‚îÇ
‚îÇ     ‚îú‚îÄ –†—É—Å—Å–∫–∏–π —è–∑—ã–∫: –æ—Ç–ª–∏—á–Ω—ã–π                       ‚îÇ
‚îÇ     ‚îú‚îÄ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑: –∏–¥–µ–∞–ª–µ–Ω                  ‚îÇ
‚îÇ     ‚îú‚îÄ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: 12GB (Q5)                     ‚îÇ
‚îÇ     ‚îî‚îÄ –¢—Ä–µ–±—É–µ—Ç GPU: RTX 4090+ (24GB VRAM)           ‚îÇ
‚îÇ                                                      ‚îÇ
‚îÇ  üöÄ –í–¢–û–†–ê–Ø –ú–û–î–ï–õ–¨: Mistral 14B (–≤ Q5 quantization) ‚îÇ
‚îÇ     ‚îú‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å: 50-80 token/sec                    ‚îÇ
‚îÇ     ‚îú‚îÄ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: 6GB (Q5)                      ‚îÇ
‚îÇ     ‚îú‚îÄ –ò–¥–µ–∞–ª—å–Ω–∞ –¥–ª—è chat                            ‚îÇ
‚îÇ     ‚îú‚îÄ –ú–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ CPU –µ—Å–ª–∏ –Ω—É–∂–Ω–æ                 ‚îÇ
‚îÇ     ‚îî‚îÄ –¢—Ä–µ–±—É–µ—Ç GPU: RTX 4080+ (10GB+ VRAM)          ‚îÇ
‚îÇ                                                      ‚îÇ
‚îÇ  üíæ STORAGE: 30-40GB –Ω–∞ –¥–∏—Å–∫–µ (–æ–±–µ –º–æ–¥–µ–ª–∏)          ‚îÇ
‚îÇ  üîå DEPLOYMENT: Docker –Ω–∞ Linux (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)     ‚îÇ
‚îÇ  ‚ö° –≠–õ–ï–ö–¢–†–û–≠–ù–ï–†–ì–ò–Ø: ‚Ç¨150/–º–µ—Å—è—Ü (24/7 —Ä–∞–±–æ—Ç–∞)        ‚îÇ
‚îÇ  üí∞ HARDWARE: ‚Ç¨3,000-4,000 (RTX 4090)               ‚îÇ
‚îÇ  üìà SCALING: –î–æ 100+ –∑–∞–ø—Ä–æ—Å–æ–≤/—á–∞—Å –Ω–∞ –æ–¥–Ω–æ–π –º–∞—à–∏–Ω–µ   ‚îÇ
‚îÇ                                                      ‚îÇ
‚îÇ  üéØ –†–ï–ó–£–õ–¨–¢–ê–¢:                                       ‚îÇ
‚îÇ     ‚úÖ ‚Ç¨5,200/–≥–æ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (vs Gemini API)        ‚îÇ
‚îÇ     ‚úÖ 97% —Ç–æ—á–Ω–æ—Å—Ç—å (vs 95% Gemini)                 ‚îÇ
‚îÇ     ‚úÖ 0-–∑–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏ offline                       ‚îÇ
‚îÇ     ‚úÖ –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –¥–∞–Ω–Ω—ã–º–∏                  ‚îÇ
‚îÇ     ‚úÖ 10-12 –º–µ—Å—è—Ü–µ–≤ –æ–∫—É–ø–∞–µ–º–æ—Å—Ç–∏                    ‚îÇ
‚îÇ                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

**üìã –î–û–ö–£–ú–ï–ù–¢ –ó–ê–í–ï–†–®–ï–ù**

*–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø—É—Ç—å: –ù–∞—á–∞—Ç—å —Å Qwen 32B + Mistral 14B, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Ollama –¥–ª—è deployment, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ –º–µ—Ä–µ —Ä–æ—Å—Ç–∞ –Ω–∞–≥—Ä—É–∑–∫–∏.*
