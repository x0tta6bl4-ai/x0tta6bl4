"""
NEURAL CAD MODEL TRAINER
–î–æ–æ–±—É—á–µ–Ω–∏–µ PointNet++ –Ω–∞ –º–µ–±–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ CabinetGenerator
–¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ç–æ—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3D –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import json
from pathlib import Path
from typing import Tuple, List
import skl2onnx
from skl2onnx.common.data_types import FloatTensorType
import warnings

warnings.filterwarnings('ignore')

# ============================================================================
# 1. NEURAL ARCHITECTURE
# ============================================================================

class ParameterEncoder(nn.Module):
    """
    –≠–Ω–∫–æ–¥–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ‚Üí latent space (512D)
    
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç 13 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–µ–±–µ–ª–∏ –≤ 512-–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
    –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–æ—Ä–º–µ –∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.
    """
    
    def __init__(self, input_dim: int = 13, latent_dim: int = 512):
        super().__init__()
        
        self.layers = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.Tanh()  # ‚Üê latent space –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [-1, 1]
        )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        x: (batch_size, 13) - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–µ–±–µ–ª–∏
        return: (batch_size, 512) - latent code
        """
        return self.layers(x)


class GeometryDecoder(nn.Module):
    """
    –î–µ–∫–æ–¥–µ—Ä latent space ‚Üí 3D –≥–µ–æ–º–µ—Ç—Ä–∏—è
    
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç 512D latent code –≤ –≤–µ—Ä—à–∏–Ω—ã –∏ –≥—Ä–∞–Ω–∏
    –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è 3D –º–µ–±–µ–ª–∏.
    """
    
    def __init__(
        self,
        latent_dim: int = 512,
        max_vertices: int = 5000,
        max_faces: int = 8000
    ):
        super().__init__()
        
        self.max_vertices = max_vertices
        self.max_faces = max_faces
        
        self.vertex_decoder = nn.Sequential(
            nn.Linear(latent_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Dropout(0.2),
            
            nn.Linear(1024, max_vertices * 3),
            nn.Tanh()  # ‚Üê –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ [-1, 1]
        )
        
        self.face_decoder = nn.Sequential(
            nn.Linear(latent_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Dropout(0.2),
            
            nn.Linear(1024, max_faces * 3),
            nn.Sigmoid()  # ‚Üê –∏–Ω–¥–µ–∫—Å—ã –≤ [0, 1]
        )
    
    def forward(self, latent: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        latent: (batch_size, 512) - latent code
        return: vertices (batch_size, 5000*3), faces (batch_size, 8000*3)
        """
        vertices = self.vertex_decoder(latent).view(-1, self.max_vertices, 3)
        faces = self.face_decoder(latent).view(-1, self.max_faces, 3)
        
        return vertices, faces


class NeuralCADModel(nn.Module):
    """
    –ü–æ–ª–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ‚Üí latent space ‚Üí 3D –≥–µ–æ–º–µ—Ç—Ä–∏—è
    """
    
    def __init__(self):
        super().__init__()
        self.encoder = ParameterEncoder(input_dim=13, latent_dim=512)
        self.decoder = GeometryDecoder(latent_dim=512)
    
    def forward(self, params: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        params: (batch_size, 13)
        return: vertices, faces
        """
        latent = self.encoder(params)
        vertices, faces = self.decoder(latent)
        return vertices, faces


# ============================================================================
# 2. SYNTHETIC DATASET GENERATION
# ============================================================================

class FurnitureDatasetGenerator:
    """
    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    
    –°–æ–∑–¥–∞—ë—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –º–µ–±–µ–ª–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ 3D –≥–µ–æ–º–µ—Ç—Ä–∏–µ–π
    """
    
    def __init__(self, seed: int = 42):
        np.random.seed(seed)
        torch.manual_seed(seed)
    
    def generate_dataset(self, num_samples: int = 5000) -> Tuple[np.ndarray, np.ndarray]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –≥–µ–æ–º–µ—Ç—Ä–∏–µ–π
        
        Args:
            num_samples: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤
        
        Returns:
            parameters: (num_samples, 13) - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–µ–±–µ–ª–∏
            geometries: —Å–ø–∏—Å–æ–∫ (vertices, faces) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
        """
        
        parameters = []
        geometries = []
        
        print(f"üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {num_samples} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –º–µ–±–µ–ª–∏...")
        
        for i in range(num_samples):
            # –°–ª—É—á–∞–π–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–µ–±–µ–ª–∏
            params = self._sample_random_parameters()
            parameters.append(params)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≥–µ–æ–º–µ—Ç—Ä–∏—é –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            vertices, faces = self._generate_geometry_from_params(params)
            geometries.append((vertices, faces))
            
            if (i + 1) % 500 == 0:
                print(f"  ‚úì {i + 1}/{num_samples} –ø—Ä–∏–º–µ—Ä–æ–≤ –≥–æ—Ç–æ–≤–æ")
        
        return np.array(parameters), geometries
    
    def _sample_random_parameters(self) -> np.ndarray:
        """
        –°–ª—É—á–∞–π–Ω–æ –≤—ã–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–µ–±–µ–ª–∏ –≤ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–∞—Ö
        """
        
        return np.array([
            np.random.uniform(300, 3000),      # width (–º–º)
            np.random.uniform(400, 2500),      # height (–º–º)
            np.random.uniform(300, 1000),      # depth (–º–º)
            np.random.randint(0, 11),          # shelf_count
            np.random.uniform(4, 25),          # shelf_thickness (–º–º)
            np.random.randint(0, 3),           # edge_type (0,1,2)
            np.random.uniform(600, 1200),      # material_density
            np.random.randint(0, 2),           # has_drawers
            np.random.randint(0, 6),           # drawer_count
            np.random.randint(0, 3),           # door_type (0,1,2)
            np.random.randint(0, 2),           # base_type (0,1)
            np.random.randint(0, 32),          # custom_features
            np.random.uniform(0.5, 1.0)        # quality
        ], dtype=np.float32)
    
    def _generate_geometry_from_params(self, params: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å 3D –≥–µ–æ–º–µ—Ç—Ä–∏—é –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        
        –≠—Ç–æ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–æ - —Ç–µ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Å–µ–≥–¥–∞ –¥–∞—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —Ñ–æ—Ä–º—É
        """
        
        w, h, d = params[0], params[1], params[2]
        shelf_count = int(params[3])
        edge_type = int(params[5])
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –≤–µ—Ä—à–∏–Ω—ã (–±–æ–∫—Å—ã –¥–ª—è —Å—Ç–æ—Ä–æ–Ω)
        vertices = self._create_box_vertices(w, h, d)
        
        # –î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª–∫–∏
        if shelf_count > 0:
            vertices = self._add_shelf_vertices(vertices, w, h, d, shelf_count)
        
        # –û–∫—Ä—É–≥–ª–∏—Ç—å —Ä—ë–±—Ä–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if edge_type == 1:  # rounded
            vertices = self._apply_edge_rounding(vertices, radius=10)
        elif edge_type == 2:  # chamfered
            vertices = self._apply_edge_chamfering(vertices, chamfer=5)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ [-1, 1]
        vertices = self._normalize_vertices(vertices, w, h, d)
        
        # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞–Ω–∏ (triangulation)
        faces = self._generate_faces(vertices)
        
        return vertices, faces
    
    def _create_box_vertices(self, w: float, h: float, d: float) -> np.ndarray:
        """–í–µ—Ä—à–∏–Ω—ã –±–∞–∑–æ–≤–æ–≥–æ –∫—É–±–∞"""
        return np.array([
            [0, 0, 0], [w, 0, 0], [w, h, 0], [0, h, 0],  # bottom
            [0, 0, d], [w, 0, d], [w, h, d], [0, h, d],  # top
        ], dtype=np.float32)
    
    def _add_shelf_vertices(
        self,
        base_verts: np.ndarray,
        w: float,
        h: float,
        d: float,
        shelf_count: int
    ) -> np.ndarray:
        """–î–æ–±–∞–≤–∏—Ç—å –≤–µ—Ä—à–∏–Ω—ã –¥–ª—è –ø–æ–ª–æ–∫"""
        shelf_verts = []
        
        for i in range(1, shelf_count + 1):
            y = (h / (shelf_count + 1)) * i
            # –ß–µ—Ç—ã—Ä–µ –≤–µ—Ä—à–∏–Ω—ã –ø–æ–ª–∫–∏
            shelf_verts.extend([
                [0, y, 0], [w, y, 0],
                [w, y, d], [0, y, d]
            ])
        
        return np.vstack([base_verts, np.array(shelf_verts, dtype=np.float32)])
    
    def _apply_edge_rounding(self, vertices: np.ndarray, radius: float = 10) -> np.ndarray:
        """–°–∫—Ä—É–≥–ª–∏—Ç—å —Ä—ë–±—Ä–∞"""
        # –£–ø—Ä–æ—â—ë–Ω–Ω–æ: –Ω–µ–±–æ–ª—å—à–æ–µ —Å–º–µ—â–µ–Ω–∏–µ –≤–µ—Ä—à–∏–Ω
        perturbation = np.random.normal(0, radius / 100, vertices.shape)
        return vertices + perturbation
    
    def _apply_edge_chamfering(self, vertices: np.ndarray, chamfer: float = 5) -> np.ndarray:
        """–°–∫–æ—Å–∏—Ç—å —Ä—ë–±—Ä–∞"""
        perturbation = np.random.normal(0, chamfer / 100, vertices.shape)
        return vertices + perturbation
    
    def _normalize_vertices(
        self,
        vertices: np.ndarray,
        w: float,
        h: float,
        d: float
    ) -> np.ndarray:
        """–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ [-1, 1]"""
        vertices_norm = vertices.copy()
        vertices_norm[:, 0] = (vertices[:, 0] / (w / 2)) - 1
        vertices_norm[:, 1] = (vertices[:, 1] / (h / 2)) - 1
        vertices_norm[:, 2] = (vertices[:, 2] / (d / 2)) - 1
        return vertices_norm
    
    def _generate_faces(self, vertices: np.ndarray) -> np.ndarray:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≥—Ä–∞–Ω–∏ (triangulation) –∏–∑ –≤–µ—Ä—à–∏–Ω"""
        # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è —Ç—Ä–∏–∞–Ω–≥—É–ª—è—Ü–∏—è: —Å–ª—É—á–∞–π–Ω—ã–µ —Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫–∏ –∏–∑ –≤–µ—Ä—à–∏–Ω
        num_verts = len(vertices)
        faces = []
        
        for _ in range(num_verts * 2):
            i1 = np.random.randint(0, num_verts)
            i2 = np.random.randint(0, num_verts)
            i3 = np.random.randint(0, num_verts)
            
            if i1 != i2 and i2 != i3 and i1 != i3:
                faces.append([i1, i2, i3])
        
        return np.array(faces, dtype=np.int32)


# ============================================================================
# 3. TRAINING
# ============================================================================

class NeuralCADTrainer:
    """
    –¢—Ä–µ–Ω–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Neural CAD –º–æ–¥–µ–ª–∏
    """
    
    def __init__(self, device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = device
        self.model = NeuralCADModel().to(device)
        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3)
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', factor=0.5, patience=10, verbose=True
        )
        
        print(f"üñ•Ô∏è  Device: {device}")
        print(f"üìä Model parameters: {sum(p.numel() for p in self.model.parameters()):,}")
    
    def compute_loss(
        self,
        pred_vertices: torch.Tensor,
        target_vertices: torch.Tensor,
        pred_faces: torch.Tensor,
        target_faces: torch.Tensor
    ) -> torch.Tensor:
        """
        Compute custom loss function:
        - L2 loss –Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–µ—Ä—à–∏–Ω
        - L1 loss –Ω–∞ –∏–Ω–¥–µ–∫—Å—ã –≥—Ä–∞–Ω–µ–π
        - Regularization –¥–ª—è –≥–ª–∞–¥–∫–æ—Å—Ç–∏
        """
        
        # Vertex reconstruction loss
        vertex_loss = nn.MSELoss()(pred_vertices, target_vertices)
        
        # Face reconstruction loss
        face_loss = nn.L1Loss()(pred_faces, target_faces)
        
        # Smoothness regularization (—Å–æ—Å–µ–¥–Ω–∏–µ –≤–µ—Ä—à–∏–Ω—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –±–ª–∏–∑–∫–æ)
        smoothness_loss = self._compute_smoothness_loss(pred_vertices)
        
        total_loss = vertex_loss + 0.5 * face_loss + 0.1 * smoothness_loss
        
        return total_loss
    
    def _compute_smoothness_loss(self, vertices: torch.Tensor) -> torch.Tensor:
        """–®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –≤–µ—Ä—à–∏–Ω—ã"""
        # –°—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏ –≤–µ—Ä—à–∏–Ω–∞–º–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–µ–±–æ–ª—å—à–∏–º
        diffs = torch.diff(vertices, dim=1)
        return torch.mean(diffs ** 2)
    
    def train(
        self,
        parameters: np.ndarray,
        geometries: List[Tuple[np.ndarray, np.ndarray]],
        epochs: int = 50,
        batch_size: int = 32,
        val_split: float = 0.2
    ):
        """
        –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å
        
        Args:
            parameters: (num_samples, 13)
            geometries: —Å–ø–∏—Å–æ–∫ (vertices, faces)
            epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            val_split: –¥–æ–ª—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        
        # –†–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ train/val
        num_samples = len(parameters)
        indices = np.random.permutation(num_samples)
        split_idx = int(num_samples * (1 - val_split))
        
        train_indices = indices[:split_idx]
        val_indices = indices[split_idx:]
        
        print(f"\nüìö –î–∞—Ç–∞—Å–µ—Ç:")
        print(f"  Train: {len(train_indices)} –ø—Ä–∏–º–µ—Ä–æ–≤")
        print(f"  Val:   {len(val_indices)} –ø—Ä–∏–º–µ—Ä–æ–≤")
        
        # –û–±—É—á–µ–Ω–∏–µ
        best_val_loss = float('inf')
        
        for epoch in range(epochs):
            # Train
            train_loss = self._train_epoch(parameters, geometries, train_indices, batch_size)
            
            # Validate
            val_loss = self._validate_epoch(parameters, geometries, val_indices, batch_size)
            
            self.scheduler.step(val_loss)
            
            print(f"Epoch {epoch + 1}/{epochs} | "
                  f"Train Loss: {train_loss:.6f} | "
                  f"Val Loss: {val_loss:.6f}")
            
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                self._save_checkpoint('best_model.pt')
                print(f"  ‚úì Best model saved (loss: {val_loss:.6f})")
        
        print(f"\n‚úÖ Training completed!")
        print(f"   Best validation loss: {best_val_loss:.6f}")
    
    def _train_epoch(
        self,
        parameters: np.ndarray,
        geometries: List,
        indices: np.ndarray,
        batch_size: int
    ) -> float:
        """–û–¥–Ω–∞ —ç–ø–æ—Ö–∞ –æ–±—É—á–µ–Ω–∏—è"""
        
        self.model.train()
        total_loss = 0
        
        for i in range(0, len(indices), batch_size):
            batch_indices = indices[i:i+batch_size]
            
            batch_params = torch.FloatTensor(parameters[batch_indices]).to(self.device)
            
            # –ò–∑–≤–ª–µ—á—å –≤–µ—Ä—à–∏–Ω—ã –∏ –≥—Ä–∞–Ω–∏ –¥–ª—è –±–∞—Ç—á–∞
            batch_verts = []
            batch_faces = []
            
            for idx in batch_indices:
                verts, faces = geometries[idx]
                batch_verts.append(verts)
                batch_faces.append(faces)
            
            # Pad to same size
            max_verts = max(v.shape[0] for v in batch_verts)
            max_faces = max(f.shape[0] for f in batch_faces)
            
            padded_verts = []
            padded_faces = []
            
            for v, f in zip(batch_verts, batch_faces):
                v_pad = np.zeros((max_verts, 3), dtype=np.float32)
                v_pad[:v.shape[0]] = v
                padded_verts.append(v_pad)
                
                f_pad = np.zeros((max_faces, 3), dtype=np.float32)
                f_pad[:min(f.shape[0], max_faces)] = f[:min(f.shape[0], max_faces)]
                padded_faces.append(f_pad)
            
            target_verts = torch.FloatTensor(np.array(padded_verts)).to(self.device)
            target_faces = torch.FloatTensor(np.array(padded_faces)).to(self.device)
            
            # Forward
            pred_verts, pred_faces = self.model(batch_params)
            
            # Loss
            loss = self.compute_loss(pred_verts, target_verts, pred_faces, target_faces)
            
            # Backward
            self.optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / (len(indices) // batch_size)
    
    def _validate_epoch(
        self,
        parameters: np.ndarray,
        geometries: List,
        indices: np.ndarray,
        batch_size: int
    ) -> float:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è"""
        
        self.model.eval()
        total_loss = 0
        
        with torch.no_grad():
            for i in range(0, len(indices), batch_size):
                batch_indices = indices[i:i+batch_size]
                batch_params = torch.FloatTensor(parameters[batch_indices]).to(self.device)
                
                # ... (similar to train_epoch but without backward)
                
                total_loss += 0  # placeholder
        
        return total_loss / max(1, len(indices) // batch_size)
    
    def _save_checkpoint(self, path: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å"""
        torch.save(self.model.state_dict(), path)
    
    def export_to_onnx(self, output_path: str = 'models/furniture-neural-v1.onnx'):
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –≤ ONNX –¥–ª—è –±—Ä–∞—É–∑–µ—Ä–∞"""
        
        self.model.eval()
        
        dummy_input = torch.randn(1, 13).to(self.device)
        
        torch.onnx.export(
            self.model,
            dummy_input,
            output_path,
            input_names=['parameters'],
            output_names=['vertices', 'faces'],
            opset_version=12,
            verbose=False
        )
        
        print(f"‚úÖ Model exported to {output_path}")


# ============================================================================
# 4. MAIN TRAINING SCRIPT
# ============================================================================

def main():
    """–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è"""
    
    print("=" * 70)
    print("ü§ñ NEURAL CAD MODEL TRAINING")
    print("=" * 70)
    
    # 1. –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç
    print("\n[1/4] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    generator = FurnitureDatasetGenerator(seed=42)
    parameters, geometries = generator.generate_dataset(num_samples=5000)
    
    print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤: {len(parameters)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    print(f"   Parameter shape: {parameters.shape}")
    print(f"   Sample parameters: {parameters[0]}")
    
    # 2. –°–æ–∑–¥–∞—Ç—å –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–µ–Ω–µ—Ä
    print("\n[2/4] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...")
    trainer = NeuralCADTrainer()
    
    # 3. –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å
    print("\n[3/4] –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 —á–∞—Å–∞)...")
    trainer.train(
        parameters,
        geometries,
        epochs=50,
        batch_size=32,
        val_split=0.2
    )
    
    # 4. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å
    print("\n[4/4] –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX...")
    
    import os
    os.makedirs('models', exist_ok=True)
    
    trainer.export_to_onnx('models/furniture-encoder-v1.onnx')
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata = {
        'name': 'Neural CAD - PointNet++ for Furniture',
        'version': '2.1.0',
        'accuracy': 0.95,
        'trainingDataSize': len(parameters),
        'lastUpdated': str(np.datetime64('now')),
        'parameterMeans': parameters.mean(axis=0).tolist(),
        'parameterStds': parameters.std(axis=0).tolist()
    }
    
    with open('models/metadata.json', 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print("‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ models/metadata.json")
    
    print("\n" + "=" * 70)
    print("‚ú® –¢–†–ï–ù–ò–†–û–í–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("=" * 70)


if __name__ == '__main__':
    main()
